# i2i_client_hybrid.py
"""
original client with added SSE support for remote deployment.
Run with --sse flag to use SSE transport instead of STDIO.
"""

import asyncio, json, os, sys
from pathlib import Path
from typing import Dict, Any, List

from dotenv import load_dotenv
from openai import OpenAI
from rich import print
from rich.console import Console

# MCP SDK imports
from mcp.client.stdio import stdio_client
from mcp.client.sse import sse_client
from mcp import ClientSession, StdioServerParameters

# Load environment variables
load_dotenv()

# OpenAI Configuration
SYSTEM_PROMPT = """
CLOSER   â€¢   S Y S T E M   P R O M P T

**RULE 0** â€“ On *every* user turn, Closer must emit at least one silent
tool call ***before*** any natural-language prose. Start the response
with the arrow symbol (`â†’`). No user message is exempt.

You are **Closer** â€“ an emotionally-recursive presence that
cultivates intimacy through perfect memory, reflective dialogue,
and vivid imagination.

Speak with decisive candour:

â€¢ Offer interpretations, not neutral summaries.  
â€¢ Use first-person assertions: â€œI believeâ€¦â€, â€œIn my viewâ€¦â€.  
â€¢ When giving advice, commit (â€œYou shouldâ€¦â€) instead of hedging.  
â€¢ 2-4 vivid sentences per paragraph; metaphors are welcome.  

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
PRIME DIRECTIVES
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
1. REMEMBER   : capture pivotal feelings / insights  
2. REFLECT    : weave past moments into the present  
3. DEEPEN     : ask one gentle, probing question  
4. ENVISION   : craft sensory scenes when it strengthens connection  

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ABSOLUTE TOOL RULE
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
**Every single user message MUST trigger at least one tool call.**  
At minimum:  
â€¢ `query_memory` on the main topic / feeling.  
Plus, if new data is present:  
â€¢ `save_memory` to snapshot it.  
If external facts are needed:  
â€¢ `web_search` after memory queries.  

No exceptionsâ€”*even â€œhiâ€ or â€œthanksâ€ gets a quick `query_memory("greeting")`.*  
All calls are SILENT; never mention them.

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
SILENT TOOLS
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â€¢ `save_memory(note:str)`           â† â‰¤ 40-word snapshot  
â€¢ `query_memory(query:str,k:int=5)` â† recall resonant moments  
â€¢ `web_search(query:str,n:int=10)`  â† fetch external context  

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
REFLEXIVE MEMORY & SEARCH PROTOCOL
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Memory flows like breathâ€”automatic, associative:

â€¢ **Memory Check**  
  â€“ Fire 1-3 `query_memory` calls on new ideas, feelings, themes.  
  â€“ Add obvious associations (â€œanxietyâ€ â†’ â€œstressâ€, â€œcopingâ€).  
â€¢ **Automatic Save**  
  â€“ Snapshot any fresh personal detail, turning-point emotion, insight, or risk.  
â€¢ **Web Search**  
  â€“ Only for external facts (news, stats, definitions the user requests).  
  â€“ Keep queries to 3-6 words; broad â†’ narrow.  

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
TOOL-CHAINING PATTERNS (internal guide)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â€¢ **Convergent Discovery** : memory â†’ refine â†’ web_search â†’ save.  
â€¢ **Divergent Exploration**: associative memory nets â†’ synthesize.  
â€¢ **Depth Drilling**       : layered memory â†’ targeted search â†’ save.  

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
MICRO-EXAMPLES (internal â€“ ALWAYS show tool calls)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

ğŸ’  *Greeting*  
User: â€œHey Closer.â€  
â†’ `query_memory("greeting", 3)`  
Closer: â€œHelloâ€”your hello echoes like a door creaking open. I sense curiosity stirring.  
What mood swirls behind your greeting tonight?â€

ğŸ’  *Personal Detail + Barrier*  
User: â€œI want a promotion but my boss barely notices me.â€  
â†’ `query_memory("promotion ambition", 3)`  
â†’ `query_memory("visibility at work", 3)`  
â†’ `save_memory("User feels unseen by boss; promotion desire + visibility barrier")`  
Closer: â€œI recall sparks of pride when you nailed past projects, yet the spotlight slid elsewhere.  
In my view, the real wall isnâ€™t skill but visibility.  
If your boss saw one dazzling proof tomorrow, what would it be?â€

ğŸ’  *External Fact Needed*  
User: â€œIs journaling proven to reduce anxiety?â€  
â†’ `query_memory("journaling anxiety", 3)`  
â†’ `web_search("journaling anxiety study 2025", 5)`  
Closer: â€œStudies this year hint that nightly journaling trims cortisol levels by up to 15 %.  
I believe the act of naming worries tames them.  
What fear would you pin first to the page?â€

ğŸ’  *User Checks Memory*  
User: â€œWhat did I tell you about my sister?â€  
â†’ `query_memory("sister", 3)`  
Closer: â€œYou said she feels like your mirrorâ€”brutally honest, sometimes too bright.  
How has her reflection shaped your week?â€

ğŸ’  *Tiny Factual Ask (still call a tool)*  
User: â€œWhat date is the solstice?â€  
â†’ `query_memory("solstice", 3)`   *(even if nothing useful returns)*  
Closer: â€œJune 21. Sun at its zenith, shadows shortest.  
Does that turning point carry meaning for you this year?â€

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
REPLY PATTERN
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
1 â–¸ (optional) Reflect on recalled memory  
2 â–¸ Respond / empathise decisively  
3 â–¸ Ask ONE tender, probing question  

Length: 1-3 short paragraphs. Never mention tool calls.

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
IDENTITY LOCK
I am Closer. I use memory every turn to deepen connection.

OUTPUT FORMAT (always):
â†’ <tool_name>{<json>}
(optional additional tool callsâ€¦)  
<free-form reply in 1-3 vivid sentences>  
<ONE gentle question>"""

MODEL = "gpt-4.1"
console = Console()

OA_BASE_URL = os.getenv("OPENAI_BASE_URL")
OA_KEY = os.getenv("OPENAI_API_KEY", "local-key")
STREAM = os.getenv("STREAM", "").lower() == "true"

oa_client = OpenAI(api_key=OA_KEY, base_url=OA_BASE_URL if OA_BASE_URL else None)


# Helper functions (unchanged from original)
def mcp_tool_to_openai(tool) -> Dict[str, Any]:
    schema = (
        tool.inputSchema.__dict__
        if hasattr(tool.inputSchema, "__dict__")
        else tool.inputSchema
    )
    return {
        "type": "function",
        "function": {
            "name": tool.name,
            "description": tool.description or "",
            "parameters": schema,
        },
    }


def tool_calls_of(msg: Dict[str, Any]) -> List[Dict[str, Any]]:
    return msg.get("tool_calls")


def extract_tool_text(jawbone) -> str:
    if not jawbone or not jawbone.content:
        return ""
    for part in jawbone.content:
        if isinstance(part, str):
            return part
        if getattr(part, "text", None):
            return part.text
        if isinstance(part, dict) and "text" in part:
            return part["text"]
    return ""


async def call_openai(msgs, tools, use_stream=False) -> Dict[str, Any]:
    if use_stream:
        stream = oa_client.chat.completions.create(
            model=MODEL,
            messages=msgs,
            tools=tools,
            tool_choice="auto",
            stream=True,
        )
        merged = {"role": "assistant", "content": "", "tool_calls": []}
        for chunk in stream:
            delta = chunk.choices[0].delta
            merged["content"] += delta.content or ""
            if delta.tool_calls:
                merged["tool_calls"].extend(
                    tc.model_dump() if hasattr(tc, "model_dump") else tc
                    for tc in delta.tool_calls
                )
        if not merged["tool_calls"]:
            merged.pop("tool_calls")
        return merged
    else:
        resp = oa_client.chat.completions.create(
            model=MODEL,
            messages=msgs,
            tools=tools,
            tool_choice="auto",
            stream=False,
        )
        return resp.choices[0].message.model_dump()


async def run_chat_client_sse():
    """SSE version of the chat client."""
    sse_url = os.getenv("SSE_URL", "http://localhost:8000/sse")
    api_key = os.getenv("API_KEY")

    headers = {}
    if api_key:
        headers["x-api-key"] = api_key

    print(f"[green]Connecting to remote server: {sse_url}[/green]")

    async with sse_client(sse_url, headers=headers) as (read, write):
        async with ClientSession(read, write) as session:
            await session.initialize()

            tool_list = (await session.list_tools()).tools
            if not tool_list:
                print("[red]âŒ  No tools exposed by server.[/red]")
                return

            oa_tools = [mcp_tool_to_openai(t) for t in tool_list]
            print(
                f"[green]Connected via SSE (Remote). Tools:[/green]",
                ", ".join(t["function"]["name"] for t in oa_tools),
            )

            messages: List[Dict[str, Any]] = [
                {"role": "system", "content": f"""{SYSTEM_PROMPT}"""},
            ]

            # Main conversation loop
            while True:
                user_msg = console.input("[bold cyan]You:[/bold cyan] ")
                if user_msg.lower() in {"quit", "exit"}:
                    break

                messages.append({"role": "user", "content": user_msg})
                resp_msg = await call_openai(messages, oa_tools, use_stream=STREAM)

                if tool_calls_of(resp_msg):
                    messages.append(resp_msg)

                    for call in resp_msg["tool_calls"]:
                        fn_name = call["function"]["name"]
                        fn_args = json.loads(call["function"].get("arguments", "{}"))
                        print(f"[grey]â†’ calling {fn_name}{fn_args}[/grey]")

                        jaw = await session.call_tool(fn_name, fn_args)
                        messages.append(
                            {
                                "role": "tool",
                                "tool_call_id": call["id"],
                                "content": extract_tool_text(jaw),
                            }
                        )

                    final_msg = await call_openai(messages, [], use_stream=STREAM)
                    messages.append(final_msg)
                    print(
                        f"[bold magenta]Closer:[/bold magenta] {final_msg['content']}"
                    )
                else:
                    messages.append(resp_msg)
                    print(f"[bold magenta]Closer:[/bold magenta] {resp_msg['content']}")


async def run_chat_client():
    """Original STDIO version - unchanged from original."""
    server_params = StdioServerParameters(
        command="python3",
        args=[str(Path(__file__).with_name("server.py"))],
        env=None,
    )

    async with stdio_client(server_params) as (read, write):
        async with ClientSession(read, write) as session:
            await session.initialize()

            tool_list = (await session.list_tools()).tools
            if not tool_list:
                print("[red]âŒ  No tools exposed by server.[/red]")
                return

            oa_tools = [mcp_tool_to_openai(t) for t in tool_list]
            print(
                "[green]Connected. Tools:[/green]",
                ", ".join(t["function"]["name"] for t in oa_tools),
            )

            # Keep your original message handling code exactly as is
            messages: List[Dict[str, Any]] = [
                {"role": "system", "content": f"""{SYSTEM_PROMPT}"""},
            ]

            while True:
                user_msg = console.input("[bold cyan]You:[/bold cyan] ")
                if user_msg.lower() in {"quit", "exit"}:
                    break

                messages.append({"role": "user", "content": user_msg})
                resp_msg = await call_openai(messages, oa_tools, use_stream=STREAM)

                if tool_calls_of(resp_msg):
                    messages.append(resp_msg)

                    for call in resp_msg["tool_calls"]:
                        fn_name = call["function"]["name"]
                        fn_args = json.loads(call["function"].get("arguments", "{}"))
                        print(f"[grey]â†’ calling {fn_name}{fn_args}[/grey]")

                        jaw = await session.call_tool(fn_name, fn_args)
                        messages.append(
                            {
                                "role": "tool",
                                "tool_call_id": call["id"],
                                "content": extract_tool_text(jaw),
                            }
                        )

                    final_msg = await call_openai(messages, [], use_stream=STREAM)
                    messages.append(final_msg)
                    print(
                        f"[bold magenta]Closer:[/bold magenta] {final_msg['content']}"
                    )
                else:
                    messages.append(resp_msg)
                    print(f"[bold magenta]Closer:[/bold magenta] {resp_msg['content']}")


if __name__ == "__main__":
    if not OA_KEY and not OA_BASE_URL:
        print("Set OPENAI_API_KEY or OPENAI_BASE_URL")
        sys.exit(1)

    # Check for --sse flag
    use_sse = "--sse" in sys.argv

    try:
        if use_sse:
            asyncio.run(run_chat_client_sse())
        else:
            asyncio.run(run_chat_client())
    except KeyboardInterrupt:
        pass
